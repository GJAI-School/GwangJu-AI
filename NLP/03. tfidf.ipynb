{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   는  을  맛  먹었다  있을까  맛있는  어떻게  먹을  어제  의  은  정말  나  수  밥  없었다  이  하면\n",
      "0  1  1  0    1    0    0    0   0   0  0  0   0  1  0  1    0  0   0\n",
      "1  0  0  1    0    0    0    0   0   1  1  1   1  0  0  1    1  1   0\n",
      "2  0  1  0    0    1    1    1   1   0  0  0   0  0  1  1    0  0   1\n",
      "          idf\n",
      "는    0.405465\n",
      "을    0.000000\n",
      "맛    0.405465\n",
      "먹었다  0.405465\n",
      "있을까  0.405465\n",
      "맛있는  0.405465\n",
      "어떻게  0.405465\n",
      "먹을   0.405465\n",
      "어제   0.405465\n",
      "의    0.405465\n",
      "은    0.405465\n",
      "정말   0.405465\n",
      "나    0.405465\n",
      "수    0.405465\n",
      "밥   -0.287682\n",
      "없었다  0.405465\n",
      "이    0.405465\n",
      "하면   0.405465\n",
      "          는    을         맛       먹었다       있을까       맛있는       어떻게        먹을  \\\n",
      "0  0.405465  0.0  0.000000  0.405465  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.0  0.405465  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.0  0.000000  0.000000  0.405465  0.405465  0.405465  0.405465   \n",
      "\n",
      "         어제         의         은        정말         나         수         밥  \\\n",
      "0  0.000000  0.000000  0.000000  0.000000  0.405465  0.000000 -0.287682   \n",
      "1  0.405465  0.405465  0.405465  0.405465  0.000000  0.000000 -0.287682   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.405465 -0.287682   \n",
      "\n",
      "        없었다         이        하면  \n",
      "0  0.000000  0.000000  0.000000  \n",
      "1  0.405465  0.405465  0.000000  \n",
      "2  0.000000  0.000000  0.405465  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# doc_list = [\n",
    "#     '안녕하세요 감사해요 잘있어요 다시 만나요',\n",
    "#     '안녕하세요 오늘도 좋은 하루 보내세요',\n",
    "#     '안녕하세요 안녕하세요 안녕하세요 오늘도 날씨가 좋네요',\n",
    "# ]\n",
    "\n",
    "doc_list = ['나는 밥을 먹었다',\n",
    "            '어제의 밥은 정말 맛이 없었다',\n",
    "            '어떻게 하면 맛있는 밥을 먹을 수 있을까']\n",
    "\n",
    "token_list = Okt().morphs(' '.join(doc_list))\n",
    "token_list = list(set(token_list))\n",
    "\n",
    "def tf(term, document):\n",
    "    # document 에서 term 의 등장 횟수를 count\n",
    "    count = 0\n",
    "    words = Okt().morphs(document)\n",
    "    \n",
    "    for i in words:\n",
    "        if i == term:\n",
    "            count+=1\n",
    "    return count\n",
    "    \n",
    "\n",
    "def idf(term):\n",
    "    # doc_list 에서 term 이 등장한 문서 수를 count\n",
    "    count = 0\n",
    "    \n",
    "    for document in doc_list:\n",
    "        if tf(term, document) != 0:\n",
    "            count+=1\n",
    "    return log(len(doc_list)/(1+count))    \n",
    "    \n",
    "def tfidf(term, document):\n",
    "    # tf * idf\n",
    "    return tf(term, document) * idf(term)\n",
    "    \n",
    "\n",
    "dtm = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    # document term matrix (문서별 단어 등장 횟수) 를 구현해보자, 3 (문서) x 13 (단어) 의 행렬을 리스트로 구성하면 된다\n",
    "    lst = [tf(term, doc) for term in token_list]\n",
    "    dtm.append(lst)\n",
    "    \n",
    "dtm_pd = pd.DataFrame(dtm, columns=token_list)\n",
    "print(dtm_pd)\n",
    "\n",
    "idf_list = []\n",
    "\n",
    "for token in token_list:\n",
    "    # 단어별로 idf의 값을 구한 리스트를 만들어보자\n",
    "    # 위 idf 함수를 이용하면 된다\n",
    "    idf_list.append(idf(token))\n",
    "    \n",
    "\n",
    "idf_pd = pd.DataFrame(idf_list, columns=['idf'], index=token_list)\n",
    "print(idf_pd)\n",
    "\n",
    "tfidf_list = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    # tfidf 를 구현해보자, 3 (문서) x 13 (단어) 의 행렬을 리스트로 구성하면 된다\n",
    "    # 내부의 요소는 모두 tfidf 값으로 구성\n",
    "    lst1 = [tf(term, doc) * idf(term) for term in token_list]\n",
    "    tfidf_list.append(lst1)\n",
    "    \n",
    "    \n",
    "\n",
    "tfidf_pd = pd.DataFrame(tfidf_list, columns=token_list)\n",
    "print(tfidf_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
